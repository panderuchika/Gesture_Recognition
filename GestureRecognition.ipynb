{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fy6cQbuYnjm4"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "# from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import abc\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIyMGwpOnjm5"
   },
   "source": [
    "We initialize the random seed to ensure that the outcomes remain relatively consistent and don't exhibit significant variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lbxACBcznjm5"
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JCtEdwV3njm6"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X0OCffMnjm6"
   },
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "s7BXbGkdnjm6"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5l3OkNwinjm7"
   },
   "outputs": [],
   "source": [
    "project_folder='Project_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cQLRAju7njm7"
   },
   "outputs": [],
   "source": [
    "# Create a function for plotting the training and validation accuracies as well as losses during the training process.\n",
    "\n",
    "def plot(data):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(data.history['loss'])   \n",
    "    axes[0].plot(data.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(data.history['categorical_accuracy'])   \n",
    "    axes[1].plot(data.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "infjahFDnjm8"
   },
   "source": [
    "## Generator\n",
    "This section is crucial in the code. The basic structure of the generator has been provided. In this generator, you'll handle image preprocessing, considering there are images of two different sizes, and you'll also create batches of video frames. Your task is to experiment with parameters like img_idx, y, z, and normalization to achieve high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kd4SNs_Rnjm8"
   },
   "outputs": [],
   "source": [
    "class ModelBuilder():\n",
    "    # initialisng the path where project data resides\n",
    "    def initialize_path(self, project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path = project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "\n",
    "    # initialising the batch size, frames to sample and the no. of epochs\n",
    "    def initialize_hyperparams(self, frames_to_sample = 30, batch_size = 20, num_epochs = 20):\n",
    "        self.frames_to_sample = frames_to_sample\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    # initialising the image properties    \n",
    "    def initialize_image_properties(self, image_height = 100, image_width = 100):\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.channels = 3\n",
    "        self.num_classes = 5\n",
    "        self.total_frames = 30\n",
    "        \n",
    "    # The generator function        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0, self.total_frames-1, self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, batch,batch_size, img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq = len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, num_batches,batch_size, img_idx,augment, remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx):\n",
    "                #performing image reading and resizing\n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                # image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "                image_resized = resize(image, (self.image_height,self.image_width))\n",
    "            \n",
    "                #normalizing the images\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    # cropping the images to have the targeted gestures and remove the noise from the images.\n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    # image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    image_resized = resize(image, (self.image_height,self.image_width))\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        \n",
    "        earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0,patience=10,verbose=1)\n",
    "        callbacks_list = [checkpoint, LR, earlystop]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9GaCxpknjm9"
   },
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Um9IQULnjm-"
   },
   "source": [
    "## Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "JrHxN9Zonjm-"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = tf.keras.optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nEd90bIxnjm-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 30, 160, 160, 16)  1312      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 30, 160, 160, 16)  0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 30, 160, 160, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 15, 80, 80, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 15, 80, 80, 32)    4128      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 15, 80, 80, 32)    0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 80, 80, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 8, 40, 40, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 8, 40, 40, 64)     16448     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 8, 40, 40, 64)     0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 40, 40, 64)    256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 4, 20, 20, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 4, 20, 20, 128)    65664     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 4, 20, 20, 128)    0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 20, 20, 128)   512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 2, 10, 10, 128)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25600)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3276928   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,374,789\n",
      "Trainable params: 3,373,925\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 16:32:03.185705: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-01-31 16:32:03.185766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14800 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:3f:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "conv_3d1 = ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=10,num_epochs=1)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQcQ8I0Tnjm_"
   },
   "source": [
    "##### Sample Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dHaxCYLMnjm_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd696fede50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_generator=ModelConv3D1()\n",
    "test_generator.initialize_path(project_folder)\n",
    "test_generator.initialize_image_properties(image_height=160,image_width=160)\n",
    "test_generator.initialize_hyperparams(frames_to_sample=30,batch_size=3,num_epochs=1)\n",
    "\n",
    "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=True)\n",
    "batch_data, batch_labels=next(g)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(batch_data[0,15,:,:,:])   \n",
    "axes[1].imshow(batch_data[3,15,:,:,:])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yli-eh5bnjm_"
   },
   "source": [
    "## Experimenting with Image resolution, number of frames to use and batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY-pLFyPnjm_"
   },
   "source": [
    "### We had hit the limit on memory resources with image resolution of 160x160 with 30 frames and batch_size of 40...we get the below error\n",
    "\n",
    "ResourceExhaustedError: OOM when allocating tensor with shape[40,16,30,160,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KbLWDKLfnjm_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory util is 3.662109524011612 Gigs\n"
     ]
    }
   ],
   "source": [
    "print(\"Memory util is {} Gigs\". format(getsizeof(np.zeros((40,16,30,160,160)))/(1024*1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPxYEd7LnjnA"
   },
   "source": [
    "##### So lets trade-off between these parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_-ZnZjNnjnA"
   },
   "source": [
    "##### Below are the experiments to see how training time is affected by image resolution, number of images in sequence and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "29NnAnYZnjnA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 900805\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 16:32:15.321489: I tensorflow/stream_executor/cuda/cuda_dnn.cc:377] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 1.5787 - categorical_accuracy: 0.4299\n",
      "Epoch 00001: val_loss improved from inf to 2.16951, saving model to model_init_2024-01-3116_32_06.557311/model-00001-1.57868-0.42986-2.16951-0.16000.h5\n",
      "23/23 [==============================] - 232s 10s/step - loss: 1.5787 - categorical_accuracy: 0.4299 - val_loss: 2.1695 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
      "Epoch 2/2\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8594 - categorical_accuracy: 0.6682\n",
      "Epoch 00002: val_loss did not improve from 2.16951\n",
      "23/23 [==============================] - 237s 11s/step - loss: 0.8594 - categorical_accuracy: 0.6682 - val_loss: 3.1557 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd75ba9e8b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_3d1 = ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height = 100, image_width = 100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample = 15, batch_size = 30, num_epochs = 2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16mEaVkJnjnA"
   },
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=20,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeI7dIF9njnA"
   },
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30,batch_size=15,num_epochs=2)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ig9tudMJnjnA"
   },
   "source": [
    "- We can observe from above experiments that \"image resolution\" and \"number of frames\" in sequence have more impact on training time than \"batch_size\"\n",
    "- We can consider the Batch Size around 15-40\n",
    "- Change the resolution 160\\*160, 120\\*120 according the model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLM5nLk7njnB"
   },
   "source": [
    "## Model 1\n",
    "### Base Model - Batch Size = 40 and No. of Epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72IrFuF_njnB"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = tf.keras.optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5JI84qUnjnB"
   },
   "outputs": [],
   "source": [
    "conv_3d1=ModelConv3D1()\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "conv_3d1.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=20,batch_size=40,num_epochs=15)\n",
    "conv_3d1_model=conv_3d1.define_model()\n",
    "conv_3d1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMm1CBqqnjnB"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "history_model1 = conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIGejajpnjnB"
   },
   "outputs": [],
   "source": [
    "plot(history_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63ujv-2BnjnB"
   },
   "source": [
    "##### Model is clearly overfitting. :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVHZK11LnjnC"
   },
   "source": [
    "## Model 2  \n",
    "### Adding dropout layers - Batch Size = 20 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3FWZnkbnjnC"
   },
   "outputs": [],
   "source": [
    "conv_3d2=ModelConv3D1()\n",
    "conv_3d2.initialize_path(project_folder)\n",
    "conv_3d2.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d2.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=25)\n",
    "conv_3d2_model=conv_3d2.define_model(dense_neurons=256,dropout=0.5)\n",
    "conv_3d2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNDPMjGgnjnC"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d2_model.count_params())\n",
    "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Akz4HqVZnjnC"
   },
   "outputs": [],
   "source": [
    "plot(history_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A48O6nM0njnC"
   },
   "source": [
    "##### We can see  val_loss did not improve from 1.24219 so earlystopping stops the epoch automatically!! \n",
    "- Last Epoch stop on 15/25!! good job earlystopping ;)\n",
    "- Best weights save automatically. The validation accuracy of 52% and training accuracy of 65%. Next we will try to reduce the filter size and image resolution and see if get better results. Moreover since we see minor oscillations  in loss, let's try lowering the learning rate to 0.0002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ckwq3LAnjnC"
   },
   "source": [
    "## Model 3 \n",
    "### Reduce filter size to (2,2,2) and image res to 120 x  120, - Batch Size = 30 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ks9wUfP3njnC"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D3(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "        \n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJGBdYDcnjnD"
   },
   "outputs": [],
   "source": [
    "conv_3d3=ModelConv3D3()\n",
    "conv_3d3.initialize_path(project_folder)\n",
    "conv_3d3.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d3.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
    "conv_3d3_model=conv_3d3.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
    "conv_3d3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9oPcMnInjnD"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d3_model.count_params())\n",
    "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ej1kWF-FnjnD"
   },
   "outputs": [],
   "source": [
    "plot(history_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgxeJI5cnjnD"
   },
   "source": [
    "##### Model has a  best validation accuracy of 72% and training accuracy of 76% . Also we were able to reduce the parameter size by half the earlier model. Let's trying adding more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvD1n0VrnjnD"
   },
   "source": [
    "## Model 4 - \n",
    "### Adding more layers - Batch Size = 20 and No. of Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMzg4lKgnjnD"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D4(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF4ZelhnnjnD"
   },
   "outputs": [],
   "source": [
    "conv_3d4=ModelConv3D4()\n",
    "conv_3d4.initialize_path(project_folder)\n",
    "conv_3d4.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d4_model=conv_3d4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
    "conv_3d4_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQc7JJX8njnE"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d4_model.count_params())\n",
    "history_model4=conv_3d4.train_model(conv_3d4_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jivNbrmTnjnE"
   },
   "outputs": [],
   "source": [
    "plot(history_model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-85eRQ9njnE"
   },
   "source": [
    "##### With more layers we dont see much performance improvement. We get a best validation accuracy of 76% . Let's try adding dropouts at the convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygcFPbOZnjnE"
   },
   "source": [
    "## Model 5 \n",
    "### Adding dropout at convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RwPQv_xnjnE"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D5(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKnmPmnAnjnE"
   },
   "outputs": [],
   "source": [
    "conv_3d5=ModelConv3D5()\n",
    "conv_3d5.initialize_path(project_folder)\n",
    "conv_3d5.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d5.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=15)\n",
    "conv_3d5_model=conv_3d5.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
    "conv_3d5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QDIsslLnjnE"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d5_model.count_params())\n",
    "history_model5=conv_3d5.train_model(conv_3d5_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c36GsiosnjnF"
   },
   "outputs": [],
   "source": [
    "plot(history_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXX9hiXHnjnF"
   },
   "source": [
    " __Ohh! Overfitting again!! Adding dropouts has further reduced validation accuracy as the model doesn't seem to generalise well.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obqq42y-njnF"
   },
   "source": [
    "##### All the experimental models above have more than 1 million parameters. Let's try to reduce the model size and see the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgDyPcp9njnF"
   },
   "source": [
    "## Model 6 \n",
    "### Reducing the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyradtXjnjnF"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D6(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jaKYBh1njnF"
   },
   "outputs": [],
   "source": [
    "conv_3d6=ModelConv3D6()\n",
    "conv_3d6.initialize_path(project_folder)\n",
    "conv_3d6.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d6.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=20)\n",
    "conv_3d6_model=conv_3d6.define_model(dense_neurons=128,dropout=0.25)\n",
    "conv_3d6_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSmmb051njnF"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d6_model.count_params())\n",
    "history_model6=conv_3d6.train_model(conv_3d6_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkJXhAcbnjnF"
   },
   "outputs": [],
   "source": [
    "plot(history_model6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSJR3wLynjnG"
   },
   "source": [
    "###### For the above low memory foot print model, we get the best validation accuracy of 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tMxr4nNnjnG"
   },
   "source": [
    "## Model 7 - Reducing the number of parameters again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUrSZIwNnjnG"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D7(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2wnjXvEnjnG"
   },
   "outputs": [],
   "source": [
    "conv_3d7=ModelConv3D7()\n",
    "conv_3d7.initialize_path(project_folder)\n",
    "conv_3d7.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d7.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d7_model=conv_3d7.define_model(dense_neurons=64,dropout=0.25)\n",
    "conv_3d7_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ec2G2xP7njnG"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d7_model.count_params())\n",
    "history_model7=conv_3d7.train_model(conv_3d7_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR8ALVXAnjnG"
   },
   "outputs": [],
   "source": [
    "plot(history_model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcgHiH0EnjnG"
   },
   "source": [
    "###### For the above low memory foot print model the best validation accuracy of 73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyWDLiI_njnG"
   },
   "source": [
    "## Model 8 - CNN- LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoUjb6T7njnH"
   },
   "outputs": [],
   "source": [
    "class RNNCNN1(ModelBuilder):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        #model.add(TimeDistributed(Conv2D(512, (2, 2) , padding='valid', activation='relu')))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "       # model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sXcBo6enjnH"
   },
   "outputs": [],
   "source": [
    "rnn_cnn1=RNNCNN1()\n",
    "rnn_cnn1.initialize_path(project_folder)\n",
    "rnn_cnn1.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn1.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "rnn_cnn1_model=rnn_cnn1.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFTCYWPWnjnH"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", rnn_cnn1_model.count_params())\n",
    "history_model8=rnn_cnn1.train_model(rnn_cnn1_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDeM4hbbnjnH"
   },
   "outputs": [],
   "source": [
    "plot(history_model8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nONq_3oXnjnH"
   },
   "source": [
    "##### For CNN - LSTM model we get a best validation accuracy of 85%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jYrHGAvnjnH"
   },
   "source": [
    "As we see more cases of overfitting, lets augment the data with ***slight rotation*** as well and run the same set of models again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYczHH8RnjnH"
   },
   "source": [
    "## Let's apply some data augmentation & check the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "yN1N2NWenjnH"
   },
   "outputs": [],
   "source": [
    "class ModelBuilderMoreAugmentation(metaclass= abc.ABCMeta):\n",
    "    \n",
    "    def initialize_path(self,project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "        self.train_path = project_folder + '/' + 'train'\n",
    "        self.val_path =  project_folder + '/' + 'val'\n",
    "        self.num_train_sequences = len(self.train_doc)\n",
    "        self.num_val_sequences = len(self.val_doc)\n",
    "        \n",
    "    def initialize_image_properties(self,image_height=100,image_width=100):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "        self.channels=3\n",
    "        self.num_classes=5\n",
    "        self.total_frames=30\n",
    "          \n",
    "    def initialize_hyperparams(self,frames_to_sample=30,batch_size=20,num_epochs=20):\n",
    "        self.frames_to_sample=frames_to_sample\n",
    "        self.batch_size=batch_size\n",
    "        self.num_epochs=num_epochs\n",
    "        \n",
    "        \n",
    "    def generator(self,source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0,self.total_frames-1,self.frames_to_sample)).astype(int)\n",
    "        batch_size=self.batch_size\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(t)//batch_size\n",
    "        \n",
    "            for batch in range(num_batches): \n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,batch,batch_size,img_idx,augment)\n",
    "                yield batch_data, batch_labels \n",
    "\n",
    "            remaining_seq=len(t)%batch_size\n",
    "        \n",
    "            if (remaining_seq != 0):\n",
    "                batch_data, batch_labels= self.one_batch_data(source_path,t,num_batches,batch_size,img_idx,augment,remaining_seq)\n",
    "                yield batch_data, batch_labels \n",
    "    \n",
    "    \n",
    "    def one_batch_data(self,source_path,t,batch,batch_size,img_idx,augment,remaining_seq=0):\n",
    "    \n",
    "        seq_len = remaining_seq if remaining_seq else batch_size\n",
    "    \n",
    "        batch_data = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels)) \n",
    "        batch_labels = np.zeros((seq_len,self.num_classes)) \n",
    "    \n",
    "        if (augment): batch_data_aug = np.zeros((seq_len,len(img_idx),self.image_height,self.image_width,self.channels))\n",
    "\n",
    "        \n",
    "        for folder in range(seq_len): \n",
    "            imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "            for idx,item in enumerate(img_idx): \n",
    "                image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                # image_resized=imresize(image,(self.image_height,self.image_width,3))\n",
    "                image_resized = resize(image, (self.image_height,self.image_width))\n",
    "            \n",
    "\n",
    "                batch_data[folder,idx,:,:,0] = (image_resized[:,:,0])/255\n",
    "                batch_data[folder,idx,:,:,1] = (image_resized[:,:,1])/255\n",
    "                batch_data[folder,idx,:,:,2] = (image_resized[:,:,2])/255\n",
    "            \n",
    "                if (augment):\n",
    "                    shifted = cv2.warpAffine(image, \n",
    "                                             np.float32([[1, 0, np.random.randint(-30,30)],[0, 1, np.random.randint(-30,30)]]), \n",
    "                                            (image.shape[1], image.shape[0]))\n",
    "                    \n",
    "                    gray = cv2.cvtColor(shifted,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0) \n",
    "                    \n",
    "                    cropped=shifted[x0:x1,y0:y1,:]\n",
    "                    \n",
    "                    # image_resized=imresize(cropped,(self.image_height,self.image_width,3))\n",
    "                    image_resized = resize(cropped, (self.image_height,self.image_width))\n",
    "                    \n",
    "                    M = cv2.getRotationMatrix2D((self.image_width//2,self.image_height//2),\n",
    "                                                np.random.randint(-10,10), 1.0)\n",
    "                    rotated = cv2.warpAffine(image_resized, M, (self.image_width, self.image_height))\n",
    "                    \n",
    "                    #shifted = cv2.warpAffine(image_resized, \n",
    "                    #                        np.float32([[1, 0, np.random.randint(-3,3)],[0, 1, np.random.randint(-3,3)]]), \n",
    "                    #                        (image_resized.shape[1], image_resized.shape[0]))\n",
    "            \n",
    "                    batch_data_aug[folder,idx,:,:,0] = (rotated[:,:,0])/255\n",
    "                    batch_data_aug[folder,idx,:,:,1] = (rotated[:,:,1])/255\n",
    "                    batch_data_aug[folder,idx,:,:,2] = (rotated[:,:,2])/255\n",
    "                \n",
    "            \n",
    "            batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "    \n",
    "        if (augment):\n",
    "            batch_data=np.concatenate([batch_data,batch_data_aug])\n",
    "            batch_labels=np.concatenate([batch_labels,batch_labels])\n",
    "\n",
    "        \n",
    "        return(batch_data,batch_labels)\n",
    "    \n",
    "    \n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc,augment=augment_data)\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "        \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "        callbacks_list = [checkpoint, LR]\n",
    "\n",
    "        if (self.num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences//self.batch_size) + 1\n",
    "    \n",
    "        history=model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1, \n",
    "                            callbacks=callbacks_list, validation_data=val_generator, \n",
    "                            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "        return history\n",
    "\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpWuos6DnjnI"
   },
   "outputs": [],
   "source": [
    "class Test(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self):\n",
    "        pass\n",
    "\n",
    "test_generator=Test()\n",
    "test_generator.initialize_path(project_folder)\n",
    "test_generator.initialize_image_properties(image_height=160,image_width=160)\n",
    "test_generator.initialize_hyperparams(frames_to_sample=30,batch_size=3,num_epochs=1)\n",
    "\n",
    "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=True)\n",
    "batch_data, batch_labels=next(g)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "axes[0].imshow(batch_data[0,29,:,:,:])   \n",
    "axes[1].imshow(batch_data[3,29,:,:,:])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-9K-bM_njnI"
   },
   "source": [
    "## Model 9 with Augmentation\n",
    "### (3,3,3) Filter & 160x160 Image resolution - similar to Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SCGY76OnjnI"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D9(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wz6R-8QnjnI"
   },
   "outputs": [],
   "source": [
    "conv_3d9=ModelConv3D9()\n",
    "conv_3d9.initialize_path(project_folder)\n",
    "conv_3d9.initialize_image_properties(image_height=160,image_width=160)\n",
    "conv_3d9.initialize_hyperparams(frames_to_sample=20,batch_size=20,num_epochs=20)\n",
    "conv_3d9_model=conv_3d9.define_model(dense_neurons=256,dropout=0.5)\n",
    "conv_3d9_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkqnwkk4njnI"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d9_model.count_params())\n",
    "history_model9=conv_3d9.train_model(conv_3d9_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESP9o5k5njnI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(history_model9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-mzZQBMnjnJ"
   },
   "source": [
    "## Model 10 with Augmentation\n",
    "### (2,2,2) Filter  & 120x120 Image resolution - similar to Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9hT3B08njnJ"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D10(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-8PNHW2njnJ"
   },
   "outputs": [],
   "source": [
    "conv_3d10=ModelConv3D10()\n",
    "conv_3d10.initialize_path(project_folder)\n",
    "conv_3d10.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d10.initialize_hyperparams(frames_to_sample=16,batch_size=30,num_epochs=25)\n",
    "conv_3d10_model=conv_3d10.define_model(filtersize=(2,2,2),dense_neurons=256,dropout=0.5)\n",
    "conv_3d10_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orGajVMSnjnJ"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d10_model.count_params())\n",
    "history_model10=conv_3d10.train_model(conv_3d10_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRpCgZJZnjnJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(history_model10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozqKxcWDnjnJ"
   },
   "source": [
    "## Model 11 with Augmentation\n",
    "### Adding more layers - Similar to model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K01vH6_0njnJ"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D11(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3aO3Q6YnjnJ"
   },
   "outputs": [],
   "source": [
    "conv_3d11=ModelConv3D11()\n",
    "conv_3d11.initialize_path(project_folder)\n",
    "conv_3d11.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d11.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d11_model=conv_3d11.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
    "conv_3d11_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMd_kv_injnK"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d11_model.count_params())\n",
    "history_model11=conv_3d11.train_model(conv_3d11_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9We3GVmnjnK"
   },
   "outputs": [],
   "source": [
    "plot(history_model11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxd-YwamnjnK"
   },
   "source": [
    "## Model 12 with Augmentation\n",
    "### Adding dropouts - Similar to Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_vwc92UnjnK"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D12(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,filtersize=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(16, filtersize, padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxSSp5w2njnK"
   },
   "outputs": [],
   "source": [
    "conv_3d12=ModelConv3D12()\n",
    "conv_3d12.initialize_path(project_folder)\n",
    "conv_3d12.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d12.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d12_model=conv_3d12.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
    "conv_3d12_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5LtaWNFnjnK"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d12_model.count_params())\n",
    "history_model12=conv_3d12.train_model(conv_3d12_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eClV1q40njnK"
   },
   "outputs": [],
   "source": [
    "plot(history_model12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kAlAcydnjnL"
   },
   "source": [
    "Model is overfitting badly !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8qq__OknjnL"
   },
   "source": [
    "## Model 13 with Augmentation\n",
    "### Reducing network parameters - Similar to Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3rwYLrAnjnL"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D13(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL6NFcV_njnL"
   },
   "outputs": [],
   "source": [
    "conv_3d13=ModelConv3D13()\n",
    "conv_3d13.initialize_path(project_folder)\n",
    "conv_3d13.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d13.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d13_model=conv_3d13.define_model(dense_neurons=128,dropout=0.25)\n",
    "conv_3d13_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOEJq6IbnjnL"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d13_model.count_params())\n",
    "history_model13=conv_3d13.train_model(conv_3d13_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5l0Z_5EGnjnL"
   },
   "outputs": [],
   "source": [
    "plot(history_model13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_925yixdnjnL"
   },
   "source": [
    "## Model 14 with Augmentation\n",
    "###  Reducing network parameters again - Similar to model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTZu3l4ZnjnL"
   },
   "outputs": [],
   "source": [
    "class ModelConv3D14(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                 input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(self.num_classes,activation='softmax'))\n",
    "\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxxDWyiDnjnM"
   },
   "outputs": [],
   "source": [
    "conv_3d14=ModelConv3D14()\n",
    "conv_3d14.initialize_path(project_folder)\n",
    "conv_3d14.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d14.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d14_model=conv_3d14.define_model(dense_neurons=64,dropout=0.25)\n",
    "conv_3d14_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uLKqCJNnjnM"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d14_model.count_params())\n",
    "history_model14=conv_3d14.train_model(conv_3d14_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYaZuRR0njnM"
   },
   "outputs": [],
   "source": [
    "plot(history_model14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PoahCF1njnM"
   },
   "source": [
    "## Model 15 with Augmentation\n",
    "### CNN LSTM with GRU - Similar to Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzyOywG_njnM"
   },
   "outputs": [],
   "source": [
    "class RNNCNN2(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),\n",
    "                                  input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        \n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9pV5J_qnjnM"
   },
   "outputs": [],
   "source": [
    "rnn_cnn2=RNNCNN2()\n",
    "rnn_cnn2.initialize_path(project_folder)\n",
    "rnn_cnn2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn2.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "rnn_cnn2_model=rnn_cnn2.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sN5pfTC2njnM"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", rnn_cnn2_model.count_params())\n",
    "history_model15=rnn_cnn2.train_model(rnn_cnn2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lMENznF9njnN"
   },
   "outputs": [],
   "source": [
    "plot(history_model15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfHcIYnsnjnN"
   },
   "source": [
    "### We see that overfitting is considerably high when we do more augmentation. However there is not much improvement on accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ8KfWaknjnN"
   },
   "source": [
    "## Model 16 - Trying out transfer learning\n",
    "__(Optional)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDEElRzbnjnN"
   },
   "outputs": [],
   "source": [
    "# importing the MobileNet model due to it's lightweight architecture and high speed performance as compared \n",
    "# to other heavy-duty models like VGG16, Alexnet, InceptionV3 etc. Also, we are now also running on low disk space \n",
    "# in the nimblebox.ai platform. \n",
    "\n",
    "from keras.applications import mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjJ549NFnjnN"
   },
   "outputs": [],
   "source": [
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class RNNCNN_TL(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    "        \n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGLAbHEinjnN"
   },
   "outputs": [],
   "source": [
    "rnn_cnn_tl=RNNCNN_TL()\n",
    "rnn_cnn_tl.initialize_path(project_folder)\n",
    "rnn_cnn_tl.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_tl.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
    "rnn_cnn_tl_model=rnn_cnn_tl.define_model(lstm_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "578TAT4GnjnN"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", rnn_cnn_tl_model.count_params())\n",
    "history_model16=rnn_cnn_tl.train_model(rnn_cnn_tl_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBnSY2jNnjnO"
   },
   "outputs": [],
   "source": [
    "plot(history_model16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7nltyhfnjnO"
   },
   "source": [
    "##### We are not training the mobilenet weights and we see validation accuracy is very poor. Let's train them as well and observe if there is performance improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqUrFjmwnjnO"
   },
   "source": [
    "## Model 17 - Transfer Learning with GRU and training all weights\n",
    "__(Optional)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKEH4oKGnjnO"
   },
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class RNNCNN_TL2(ModelBuilderMoreAugmentation):\n",
    "    \n",
    "    def define_model(self,gru_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.frames_to_sample,self.image_height,self.image_width,self.channels)))\n",
    " \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(gru_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfPQuUHenjnO"
   },
   "outputs": [],
   "source": [
    "rnn_cnn_tl2=RNNCNN_TL2()\n",
    "rnn_cnn_tl2.initialize_path(project_folder)\n",
    "rnn_cnn_tl2.initialize_image_properties(image_height=120,image_width=120)\n",
    "rnn_cnn_tl2.initialize_hyperparams(frames_to_sample=16,batch_size=5,num_epochs=20)\n",
    "rnn_cnn_tl2_model=rnn_cnn_tl2.define_model(gru_cells=128,dense_neurons=128,dropout=0.25)\n",
    "rnn_cnn_tl2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0789PSrZnjnO"
   },
   "outputs": [],
   "source": [
    "print(\"Total Params:\", rnn_cnn_tl2_model.count_params())\n",
    "history_model17=rnn_cnn_tl2.train_model(rnn_cnn_tl2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hpDDWkIpnjnO"
   },
   "outputs": [],
   "source": [
    "plot(history_model17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTevp1DDnjnO"
   },
   "source": [
    "### Awesome results! 98% Training accuracy and 93% validation accuracy :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKnyVWoUnjnP"
   },
   "source": [
    "# Consolidated Final Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBIrMamknjnP"
   },
   "source": [
    "![png1.PNG](attachment:png1.PNG)\n",
    "![png2.PNG](attachment:png2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBEtsI27njnP"
   },
   "source": [
    "## After doing all the experiments, we finalized Model 8 - CNN+LSTM, which performed well because it has \n",
    "\n",
    "  - (Training Accuracy : 93%, Validation Accuracy : 85%)\n",
    "\n",
    "  - Number of Parameters(1,657,445) less according to other models performance\n",
    "\n",
    "\n",
    "  - The best weights of CNN-LSTM: model.h5 (19 MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9avbJUAnjnP"
   },
   "source": [
    "# Loading model and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbRflQCEnjnP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from keras.models import load_model\n",
    "model = load_model('model_init_2020-06-2522_00_52.036987/model-00020-0.19649-0.93514-0.45695-0.85000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Wzg44HZnjnP"
   },
   "outputs": [],
   "source": [
    "test_generator=RNNCNN1()\n",
    "test_generator.initialize_path(project_folder)\n",
    "test_generator.initialize_image_properties(image_height=120,image_width=120)\n",
    "test_generator.initialize_hyperparams(frames_to_sample=18,batch_size=20,num_epochs=20)\n",
    "\n",
    "g=test_generator.generator(test_generator.val_path,test_generator.val_doc,augment=False)\n",
    "batch_data, batch_labels=next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1b9BasQnjnP"
   },
   "outputs": [],
   "source": [
    "batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVvUBt08njnP"
   },
   "outputs": [],
   "source": [
    "print(np.argmax(model.predict(batch_data[:,:,:,:,:]),axis=1))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aVHZK11LnjnC",
    "-Ckwq3LAnjnC",
    "KvD1n0VrnjnD",
    "ygcFPbOZnjnE",
    "dgDyPcp9njnF",
    "2tMxr4nNnjnG",
    "PyWDLiI_njnG",
    "EYczHH8RnjnH",
    "q-9K-bM_njnI",
    "E-mzZQBMnjnJ",
    "ozqKxcWDnjnJ",
    "Lxd-YwamnjnK",
    "K8qq__OknjnL",
    "_925yixdnjnL",
    "6PoahCF1njnM",
    "xfHcIYnsnjnN",
    "wQ8KfWaknjnN",
    "aqUrFjmwnjnO",
    "YTevp1DDnjnO",
    "eBEtsI27njnP"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
